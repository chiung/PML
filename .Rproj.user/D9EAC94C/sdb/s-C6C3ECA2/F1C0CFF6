{
    "contents" : "---\ntitle: \"R ML Assignment\"\nauthor: \"Peter Ho\"\ndate: \"Saturday, December 26, 2015\"\noutput: html_document\n---\n# R ML Assignment\n\n## 1.0 Introduction\nIn the Practical Machine Learning assignment, we are given data measured from acceleromters from a pool of users as they performed barbell lifts in 5 ways (which ranges from one performed using good form , to those performed using bad form). Each way of performing a barbell lift was subsequently assigned a class label, resulting in five class labels of A<B, C, D, and E. In this assignment, a training set consiting of 19622 observations is provided, with each observation consisting of 160 predictor values. For the test set, 20 observations with feature length  of 160 is also provided. The goal of the assignment is to predict the class labels for each of the 20 observations. To begin the work of solving the assignment, we load the necessary libraries using the following code:\n```{r message=FALSE, warning=FALSE}\nlibrary('caret')\nlibrary('randomForest')\nlibrary('e1071')\n```\n\n\n##2.0 Data acquisition\nData was provided through the two provided links at https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv and https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv. This data is downloaded to the chosen R project folder and is read into the R environment using the following commands. We designate NA values in the dataset to include blanks, actual NAs and Nulls.\n```{r message=FALSE, warning=FALSE}\ntraining_org<-read.csv(file=\"C:\\\\Users\\\\peyter\\\\Documents\\\\R ML Assignment\\\\pml-training.csv\",na.strings=c(\"\", \"NA\", \"NULL\"))\ntesting_org<-read.csv(file=\"C:\\\\Users\\\\peyter\\\\Documents\\\\R ML Assignment\\\\pml-testing.csv\",na.strings=c(\"\", \"NA\", \"NULL\"))\n```\n\n##3.0 Preprocess data\nThe training and testing datasets were further preprocessed, with the following steps:\n\n###3.1 Removal of predictor variables which contains too many NAs, as well as irrelevant predictor variables.\n```{r message=FALSE, warning=FALSE}\n#preprocess training_org by removing NA values\ntrainingNApp<- training_org[ , colSums(is.na(training_org)) == 0]\nfilter1 = c('X', 'user_name', 'raw_timestamp_part_1', 'raw_timestamp_part_2', 'cvtd_timestamp', 'new_window', 'num_window')\ntraining_filter <- trainingNApp[, -which(names(trainingNApp) %in% filter1)]\n#preprocess testing_org by removing NA values\ntestingNApp<- testing_org[ , colSums(is.na(testing_org)) == 0]\nfilter1 = c('X', 'user_name', 'raw_timestamp_part_1', 'raw_timestamp_part_2', 'cvtd_timestamp', 'new_window', 'num_window')\ntesting_filter <- testingNApp[, -which(names(testingNApp) %in% filter1)]\n```\n\n###3.2 Examine predictor variables for low variance\n```{r message=FALSE, warning=FALSE}\n#continue preprocess by removing near zero variance for training\nzeroVar= nearZeroVar(training_filter[sapply(training_filter, is.numeric)], saveMetrics = TRUE)\ntraining.nonzerovar = training_filter[,zeroVar[, 'nzv']==0]\n#continue preprocess by removing near zero variance for testing\nzeroVartest= nearZeroVar(testing_filter[sapply(testing_filter, is.numeric)], saveMetrics = TRUE)\ntesting.nonzerovar = testing_filter[,zeroVar[, 'nzv']==0]\n```\n\n###3.3 Remove highly correlated predictor variables\n```{r message=FALSE, warning=FALSE}\n#continue preprocess by removing highly correlated predictor variable for training\ncorrMatrix <- cor(na.omit(training.nonzerovar[sapply(training.nonzerovar, is.numeric)]))\nremovecor = findCorrelation(corrMatrix, cutoff = .90, verbose = TRUE)\ntraining.decor = training.nonzerovar[,-removecor]\n#continue preprocess by removing highly correlated predictor variable for testing\ncorrMatrixtest <- cor(na.omit(testing.nonzerovar[sapply(testing.nonzerovar, is.numeric)]))\nremovecortest = findCorrelation(corrMatrixtest, cutoff = .90, verbose = TRUE)\ntesting.decor = testing.nonzerovar[,-removecor]\n```\n\nUpon completion of the preprocessing process, the dimensionality of both the training and testing set has been reduced, with each set having 46 predictor variables.\n\n##4.0 Cross validation\n\n###4.1 Partitioning the pre-processed training set\nAs the training set provided for this assignment does not have the class label \"classe\", cross validation is performed by examining the in sample error. This process is started by partitioning the pre-processed training set into a sub-training and sub-testing set as shown in the code chunk below. Here, we chose a 70:30 split between the sub-training and sub-testing set.\n```{r message=FALSE, warning=FALSE}\ninTrain <- createDataPartition(y=training.decor$classe, p=0.7, list=FALSE)\ntraining <- training.decor[inTrain,]\ntesting <- training.decor[-inTrain,]\n```\n\n###4.2 Classification using the GBM algorithm in the caret package\nI chose the GBM algorithm, as I expected that it's performance will surpass that of a decision tree, and that of Random Forest ensemble, as GBM is a boosted algorithm. The main weakness of using GBM was the long training time to acquire a model, which slowed down the time for experiments. The code to create the GBM model using the sub-training set, and the prediction using the sub-testing set is shown below , without execution (rerunning the model each time the HTML code is rendered from markdown would be horribly time consuming!). The code to show the generation of the confusion matrix is shown as well.\n```{r message=FALSE, warning=FALSE, eval=FALSE}\ngbm_model1<-train(classe ~ ., method=\"gbm\", data=training)\ngbm_predict1 <- predict(gbm_model1,newdata=testing)\nconfusionMatrix(gbm_predict1, testing$classe)\n```\n\nThe confusion matrix is shown below:\n\n![Confusion Matrix](ConfusionMatrix1.jpg)\n\n##5.0 Classifying the test set and printing the results to file\nThe GBM model gave reasonable performance, and it was then used to classify the test set for this assignment, using the following code:\n```{r message=FALSE, warning=FALSE, eval=FALSE}\n#test on actual data\ngbm_predict2<-predict(gbm_model1, newdata=testing.decor)\n#function to write labels\npml_write_files = function(x){\n  n = length(x)\n  for(i in 1:n){\n    filename = paste0(\"problem_id_\",i,\".txt\")\n    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)\n  }\n}\n#write to files\npml_write_files(gbm_predict2)\n```\n\n##6.0 Conclusions\nThe key to completing this assignment was in choosing the best set of predictor variables, using variance and correlation as clues to eliminate unneeded columns. This approach was tidier than attempting to simulate missing values using knnImpute, as some predictor variables (columns) was simply too sparse for adequate replacement. \nAnother thing to consider is the long training time necessary for models based on Random Forest (including GBM), and in future, perhaps running models in parallel might be the way to move forward.\n\n",
    "created" : 1451123124738.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4076073057",
    "id" : "F1C0CFF6",
    "lastKnownWriteTime" : 1451153030,
    "path" : "~/R ML Assignment/index.Rmd",
    "project_path" : "index.Rmd",
    "properties" : {
        "tempName" : "Untitled2"
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}